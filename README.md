To run this application you will need to install the ollama model locally.

To do this go to https://ollama.com/download/linux and download for your environment

Once installed run the command ollama run llama3

This will run the model on port 11434
